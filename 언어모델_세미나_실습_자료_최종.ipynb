{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RDdaXxTuZ-oa"
      },
      "source": [
        "# [오피니언 라이브 언어모델 세미나 실습]\n",
        "## BERT를 이용한 소비자 리뷰 긍/부정 감성분류\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pH2OUSs8tdg9"
      },
      "source": [
        "## 실습 요약"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oZtcUJkERwfC"
      },
      "source": [
        "1. 본 실습에서는 사전 학습된 BERT를 활용하여 감성분석 모델을 구축합니다\n",
        "2. 학습된 모델을 활용하여 평가를 진행합니다.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XvnpBm1PtVeV"
      },
      "source": [
        "------"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xVvGtj7vYQ5v"
      },
      "source": [
        "### STEP 0. 환경 구축하기\n",
        "* 필요한 library들을 import 합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2r1Mx6hZs8N",
        "outputId": "7d57d272-2f81-4fa8-9d4b-654b7a5c9920"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBWSfQGI-a8F",
        "outputId": "736e548e-306f-4958-c5d0-9eab00fea27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "현재 위치: /home/doyoon/teaching/NLP-example\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings( 'ignore' )\n",
        "\n",
        "# GPU Setting\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.chdir(os.getcwd())\n",
        "print(f\"현재 위치: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtIPKkNiaosp",
        "outputId": "fdef2965-7d92-4469-8374-999cf0d30450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version:[3.8.10 (default, Mar 15 2022, 12:22:08) \n",
            "[GCC 9.4.0]].\n",
            "PyTorch version:[1.12.0+cu102].\n",
            "device:[cuda:0].\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "#%matplotlib inline #생성한 figure를 notebook에서 볼 수있게 해주는 코드\n",
        "\n",
        "import gensim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#check torch version & device\n",
        "print (\"Python version:[%s].\"%(sys.version))\n",
        "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print (\"device:[%s].\"%(device)) # device에 cuda:0가 프린트 된다면 GPU를 사용하는 상태입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie8Y84-3yCz0",
        "outputId": "81fd47ae-47b4-4d65-bfcf-c7fe7ea074d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /transformers/src (4.21.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rUM2BsZMcCzC"
      },
      "outputs": [],
      "source": [
        "# set random seed \n",
        "\n",
        "def set_seed(random_seed):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "    \n",
        "random_seed = 42\n",
        "set_seed(random_seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FACcqNcFcExO"
      },
      "source": [
        "### STEP 1. 데이터 준비하기\n",
        "금일 실습에서는 **Naver_shopping**에서 수집된 **리뷰 데이터**를 활용합니다.\n",
        "* 제품별 후기를 별점과 함께 수집한 데이터\n",
        "* 데이터셋 출처\n",
        "\n",
        "  * 1) https://github.com/songys/AwesomeKorean_Data\n",
        "  * 2) https://github.com/bab2min/corpus/tree/master/sentiment\n",
        "\n",
        "\n",
        "* 해당 실습에서는 전체 데이터 중 50%인 10만개의 데이터를 사용함 (긍정 : 50000개, 부정 : 50000개)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_prvLfHKcGqQ"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "with open('./data/naver_shopping.txt','r',encoding='utf-8') as f:\n",
        "  data = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeFWxr9bMOWh",
        "outputId": "337ff14f-8cab-4875-9d88-763d30b6d78a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [00:00<00:00, 776682.69it/s]\n"
          ]
        }
      ],
      "source": [
        "# 분석에 사용할 형태로 가공하기\n",
        "rate = []\n",
        "label = []\n",
        "sentence = []\n",
        "for cur_review in tqdm(data):\n",
        "  # 평점과 리뷰 문장 분리\n",
        "  cur_review = cur_review.split('\\t')\n",
        "  # 평점\n",
        "  rate.append(cur_review[0])\n",
        "  # 리뷰 문장\n",
        "  sentence.append(cur_review[1].strip('\\n'))\n",
        "  # 평점 4,5 : Positive, \n",
        "  # 평점 1,2 : Negative\n",
        "  if int(cur_review[0]) >3:\n",
        "    label.append(0) # positive\n",
        "  else:\n",
        "    label.append(1) # negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BnaQBc06MmWn"
      },
      "outputs": [],
      "source": [
        "# 데이터 프레임 형태로 변환하기\n",
        "df = {\n",
        "    \"rate\" : rate,\n",
        "    \"label\" : label,\n",
        "    \"sentence\" : sentence\n",
        "}\n",
        "df = pd.DataFrame(df)\n",
        "df = df.sample(frac=0.5,replace=False, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Y51bkahCNxfU",
        "outputId": "84a9fd8c-a00a-46c2-ea8d-82bd13e7ae53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['label'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "giZkNb0_OohV",
        "outputId": "aa917edd-1376-481e-e952-320ce91e0562"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119737</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>마감이 안좋아요...실밥도 많고 바느질도 부족한 부분이 몇군데 있네요...교환받기 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72272</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>깨끗하게 잘 다듬어져 있어요. 맛도좋고요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158154</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>재구매 배송빨라요 길냥이들이 잘먹어요~~ 대용량이라 좋네요~</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65426</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>제품도 빨리 배송해주시고 꼼꼼하게 잘챙겨주셨어요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30074</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>기타 남 멋지고 예뻐요 여러 사은품도 좋아요</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       rate  label                                           sentence\n",
              "119737    2      1  마감이 안좋아요...실밥도 많고 바느질도 부족한 부분이 몇군데 있네요...교환받기 ...\n",
              "72272     5      0                            깨끗하게 잘 다듬어져 있어요. 맛도좋고요.\n",
              "158154    4      0                  재구매 배송빨라요 길냥이들이 잘먹어요~~ 대용량이라 좋네요~\n",
              "65426     5      0                         제품도 빨리 배송해주시고 꼼꼼하게 잘챙겨주셨어요\n",
              "30074     5      0                           기타 남 멋지고 예뻐요 여러 사은품도 좋아요"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vW0B011dTyOo"
      },
      "source": [
        "### STEP 2. 전처리 진행 (Preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIySBkPocmLD",
        "outputId": "dbc090aa-7452-4214-c683-3973989aaf48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['마감이 안좋아요...실밥도 많고 바느질도 부족한 부분이 몇군데 있네요...교환받기 귀찮아서 그냥 씁니다',\n",
              " '깨끗하게 잘 다듬어져 있어요. 맛도좋고요.',\n",
              " '재구매 배송빨라요 길냥이들이 잘먹어요~~ 대용량이라 좋네요~',\n",
              " '제품도 빨리 배송해주시고 꼼꼼하게 잘챙겨주셨어요',\n",
              " '기타 남 멋지고 예뻐요 여러 사은품도 좋아요',\n",
              " '기존것보다 다리를 올려놓으면 푹빠지니깐 무서워서 안올라가요.ㅠㅠ 안고 올려놓으면 가만히 있는데. 습관되면 괜찮아지겠죠.^^',\n",
              " '상품은잘받았습니다 요청한거와 손잡이방향은다르게왔지만 설치는 잘했습니다. 좀더 신경을 써주시는게 어떨까 싶네요',\n",
              " '재구매 아기땜에 하루빨리 필요했는데 배송도 오래 걸렸는데 벨크로가 안왔어요 민원처리도 답답하구요 서비스 엉망입니다',\n",
              " '좋네요. 사서 방전된 차에 점프 했는데 잘 됐습니다.',\n",
              " '저렴하게 잘샀어요ㅎ 쓰던거라 좋아요']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review_sentences = df['sentence'].to_list()\n",
        "review_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q7j4w1z-tRuy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocess(text):\n",
        "  text = re.sub('[-=+,#/\\?:^$~@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','', text) # 특수문자 제거\n",
        "  text = re.sub('[ㅠㅎㅋ]','', text) # 문자에서 많이 사용하는 ㅠ,ㅎ,ㅋ 남김\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dUBQnv6tg1f",
        "outputId": "fa0ecc1c-c9c6-420e-cbfa-c2511c021b3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:00<00:00, 266868.23it/s]\n"
          ]
        }
      ],
      "source": [
        "normalize_sentence = []\n",
        "for sentence in tqdm(review_sentences):\n",
        "  sentence = preprocess(sentence)\n",
        "  normalize_sentence.append(sentence)\n",
        "\n",
        "df['normalize_sentence'] = normalize_sentence"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zjw-KFL0k5A1"
      },
      "source": [
        "### STEP 3. 토큰화 진행 (Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ55fpYTvT0h",
        "outputId": "420ba1e1-bf96-404c-a80a-c4b204b4e411"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:09<00:00, 10834.58it/s]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
        "\n",
        "tokenized_sentence = []\n",
        "for sent in tqdm(normalize_sentence):\n",
        "  sent = tokenizer.tokenize(sent)\n",
        "  tokenized_sentence.append(sent) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XhUniskUrysU"
      },
      "outputs": [],
      "source": [
        "df['tokenized_sentence'] = tokenized_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "_KM7W6EaOLCi",
        "outputId": "95392d86-a55c-41d8-924b-3879510c70c3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbp0lEQVR4nO3de3SV9b3n8fdHiCAVhZKoSPCEsZyWi5ZLinQ57VCZQmCmgGu8YC9yXIx0Vby0p3XEM22lVWfpaquWGaWHjpliK40MPWfManGQWly0s0QJSLl4KRHxkKgQuRWr0sL5zh/7B2efsEN2IHsHsj+vtfbK83yf3+/Zv1+x+eS57P0oIjAzs9J2RlcPwMzMup7DwMzMHAZmZuYwMDMzHAZmZgb07OoBnKjy8vKoqqrq6mGYmZ1W1q1b905EVLSun7ZhUFVVRUNDQ1cPw8zstCLpjVx1nyYyMzOHgZmZOQzMzIzT+JqBWXv+8pe/0NTUxAcffNDVQym43r17U1lZSVlZWVcPxU5TDgPrtpqamujbty9VVVVI6urhFExEsHv3bpqamhgyZEhXD8dOUz5NZN3WBx98wIABA7p1EABIYsCAASVxBGSFk3cYSOoh6UVJv0zrQyQ9L6lR0hOSzkz1Xmm9MW2vytrHnan+qqTJWfWaVGuUNK8T52clrrsHwRGlMk8rnI4cGdwGvJy1fj/wYER8BNgLzE712cDeVH8wtUPScGAmMAKoAR5JAdMDeBiYAgwHrkttzcysSPK6ZiCpEvgPwL3A3yrzZ8gVwOdTk8XAfGAhMD0tAywD/kdqPx2oi4iDwOuSGoFxqV1jRGxL71WX2r50UjMza23+/KLub9++fSxZsoSbbrqpQ7udOnUqS5YsoV+/fic+NrMOyvcC8kPAfwH6pvUBwL6IOJTWm4BBaXkQsAMgIg5J2p/aDwLWZO0zu8+OVvXLcg1C0hxgDsBFF12U59BzyOeXQmf/4rCSs2/fPh555JFjwuDQoUP07Nn2//WWL19e6KFZZ+sGv1PaPU0k6T8CuyJiXRHGc1wRsSgiqiOiuqLimK/WMDulzJs3j9dee41Ro0bxiU98gk996lNMmzaN4cMzZ0FnzJjB2LFjGTFiBIsWLTrar6qqinfeeYft27czbNgwbrzxRkaMGMGkSZN4//33u2o61s3lc83gcmCapO1AHZnTQz8E+kk68udNJdCclpuBwQBp+7nA7ux6qz5t1c1Oa/fddx8XX3wxGzZs4Hvf+x7r16/nhz/8IX/4wx8AqK2tZd26dTQ0NLBgwQJ27959zD62bt3K3Llz2bJlC/369eMXv/hFsadhJaLdMIiIOyOiMiKqyFwA/k1EfAFYBVyVms0CnkzL9WmdtP03kXnQcj0wM91tNAQYCrwArAWGpruTzkzvUd8pszM7hYwbN+5ffQ5gwYIFfPzjH2f8+PHs2LGDrVu3HtNnyJAhjBo1CoCxY8eyffv2Io3WSs3JfOjsDqBO0j3Ai8Cjqf4o8NN0gXgPmV/uRMQWSUvJXBg+BMyNiMMAkm4GVgA9gNqI2HIS4zI7JX3oQx86uvzss8/y61//mueee44+ffowYcKEnJ8T6NWr19HlHj16+DSRFUyHwiAingWeTcvb+Je7gbLbfABc3Ub/e8nckdS6vhzwVTPrVvr27cuBAwdybtu/fz/9+/enT58+vPLKK6xZsyZnO7Ni8ddRWOko8t0cAwYM4PLLL2fkyJGcddZZnH/++Ue31dTU8KMf/Yhhw4bx0Y9+lPHjxxd1bGatOQzMCmjJkiU567169eKpp57Kue3IdYHy8nI2b958tP6Nb3yj08dndoS/m8jMzBwGZmbmMDAzMxwGZmaGw8DMzHAYmJkZvrXUSsj8Z+d37v4mdO7+zj77bN59913efPNNbr31VpYtW3ZMmwkTJvD973+f6urqTn1vMx8ZmJ1iLrzwwpxBYFZIDgOzApk3bx4PP/zw0fX58+dzzz33MHHiRMaMGcMll1zCk08+eUy/7du3M3LkSADef/99Zs6cybBhw7jyyiv93URWMD5NZFYg1157LV/96leZO3cuAEuXLmXFihXceuutnHPOObzzzjuMHz+eadOmtfkM44ULF9KnTx9efvllNm7cyJgxY4o5BSshDgOzAhk9ejS7du3izTffpKWlhf79+3PBBRfwta99jdWrV3PGGWfQ3NzMzp07ueCCC3LuY/Xq1dx6660AXHrppVx66aXFnIKVEIeBWQFdffXVLFu2jLfffptrr72Wxx9/nJaWFtatW0dZWRlVVVU5v7rarNh8zcCsgK699lrq6upYtmwZV199Nfv37+e8886jrKyMVatW8cYbbxy3/6c//emjX3a3efNmNm7cWIxhWwnykYGVjM6+FTQfI0aM4MCBAwwaNIiBAwfyhS98gc997nNccsklVFdX87GPfey4/b/yla9www03MGzYMIYNG8bYsWOLNHIrNQ4DswLbtGnT0eXy8nKee+65nO3effddAKqqqo5+dfVZZ51FXV1d4QdpJa/d00SSekt6QdLvJW2R9J1U/4mk1yVtSK9RqS5JCyQ1StooaUzWvmZJ2ppes7LqYyVtSn0WqK1bK8zMrCDyOTI4CFwREe9KKgN+J+nIUzluj4jWn46ZQuZh90OBy4CFwGWSPgzcBVQDAayTVB8Re1ObG4HnyTz+sgbI/eQPMzPrdO0eGUTGu2m1LL3iOF2mA4+lfmuAfpIGApOBlRGxJwXASqAmbTsnItZERACPATNOfEpmZtZRed1NJKmHpA3ALjK/0J9Pm+5Np4IelNQr1QYBO7K6N6Xa8epNOeq5xjFHUoOkhpaWlnyGbmZmecgrDCLicESMAiqBcZJGAncCHwM+AXwYuKNQg8wax6KIqI6I6oqKikK/nZlZyejQ5wwiYh+wCqiJiLfSqaCDwP8CxqVmzcDgrG6VqXa8emWOupmZFUm7F5AlVQB/iYh9ks4CPgvcL2lgRLyV7vyZAWxOXeqBmyXVkbmAvD+1WwH8N0n9U7tJwJ0RsUfSHyWNJ3MB+Xrgv3fmJM0A5s8v7v727dvHkiVLuOmmmzq874ceeog5c+bQp0+fExucWQflc2QwEFglaSOwlsw1g18Cj0vaBGwCyoF7UvvlwDagEfgxcBNAROwB7k77WAt8N9VIbf5n6vMavpPIuoF9+/bxyCOPnFDfhx56iPfee6+TR2TWtnaPDCJiIzA6R/2KNtoHMLeNbbVAbY56AzCyvbGYnU7mzZvHa6+9xqhRo/jsZz/Leeedx9KlSzl48CBXXnkl3/nOd/jTn/7ENddcQ1NTE4cPH+Zb3/oWO3fu5M033+Qzn/kM5eXlrFq1qqunYiXAn0A2K5D77ruPzZs3s2HDBp5++mmWLVvGCy+8QEQwbdo0Vq9eTUtLCxdeeCG/+tWvANi/fz/nnnsuDzzwAKtWraK8vLyLZ2Glwl9UZ1YETz/9NE8//TSjR49mzJgxvPLKK2zdupVLLrmElStXcscdd/Db3/6Wc889t6uHaiXKRwZmRRAR3HnnnXz5y18+Ztv69etZvnw53/zmN5k4cSLf/va3u2CEVup8ZGBWIH379uXAgQMATJ48mdra2qNfRtfc3Hz0wTd9+vThi1/8Irfffjvr168/pq9ZMfjIwEpGZ99a2p4BAwZw+eWXM3LkSKZMmcLnP/95PvnJTwJw9tln87Of/YzGxkZuv/12zjjjDMrKyli4cCEAc+bMoaamhgsvvNAXkK0oHAZmBXTkwTRH3Hbbbf9q/eKLL2by5MnH9Lvlllu45ZZbCjo2s2w+TWRmZg4DMzNzGFg3l/kMZPdXKvO0wnEYWLfVu3dvdu/e3e1/UUYEu3fvpnfv3l09FDuN+QKydVuVlZU0NTVRCs++6N27N5WVle03NGuDw8C6rbKyMoYMGdLVwzA7Lfg0kZmZOQzMzMxhYGZmOAzMzIw8wkBSb0kvSPq9pC2SvpPqQyQ9L6lR0hOSzkz1Xmm9MW2vytrXnan+qqTJWfWaVGuUNK8A8zQzs+PI58jgIHBFRHwcGAXUpOcV3w88GBEfAfYCs1P72cDeVH8wtUPScGAmMAKoAR6R1ENSD+BhYAowHLgutTUzsyJpNwwi4920WpZeAVwBLEv1xcCMtDw9rZO2T5SkVK+LiIMR8TqZ5x2PS6/GiNgWEX8G6lJbMzMrkryuGaS/4DcAu4CVZB5avy8iDqUmTcCgtDwI2AGQtu8HBmTXW/Vpq25mZkWSVxhExOGIGAVUkvlL/mOFHFRbJM2R1CCpoRQ+VWpmViwdupsoIvYBq4BPAv0kHfkEcyXQnJabgcEAafu5wO7seqs+bdVzvf+iiKiOiOqKioqODN3MzI4jn7uJKiT1S8tnAZ8FXiYTClelZrOAJ9NyfVonbf9NZL4prB6Yme42GgIMBV4A1gJD091JZ5K5yFzfCXMzM7M85fPdRAOBxemunzOApRHxS0kvAXWS7gFeBB5N7R8FfiqpEdhD5pc7EbFF0lLgJeAQMDciDgNIuhlYAfQAaiNiS6fN0MzM2tVuGETERmB0jvo2MtcPWtc/AK5uY1/3AvfmqC8HlucxXjMzKwB/AtnMzBwGZmbmMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMyM/J6BPFjSKkkvSdoi6bZUny+pWdKG9Jqa1edOSY2SXpU0Oatek2qNkuZl1YdIej7Vn0jPQjYzsyLJ58jgEPD1iBgOjAfmShqetj0YEaPSazlA2jYTGAHUAI9I6pGeofwwMAUYDlyXtZ/7074+AuwFZnfS/MzMLA/thkFEvBUR69PyAeBlYNBxukwH6iLiYES8DjSSeVbyOKAxIrZFxJ+BOmC6JAFXAMtS/8XAjBOcj5mZnYAOXTOQVAWMBp5PpZslbZRUK6l/qg0CdmR1a0q1tuoDgH0RcahV3czMiiTvMJB0NvAL4KsR8UdgIXAxMAp4C/hBIQbYagxzJDVIamhpaSn025mZlYy8wkBSGZkgeDwi/gEgInZGxOGI+Gfgx2ROAwE0A4OzulemWlv13UA/ST1b1Y8REYsiojoiqisqKvIZupmZ5SGfu4kEPAq8HBEPZNUHZjW7EticluuBmZJ6SRoCDAVeANYCQ9OdQ2eSuchcHxEBrAKuSv1nAU+e3LTMzKwjerbfhMuBLwGbJG1Itb8jczfQKCCA7cCXASJii6SlwEtk7kSaGxGHASTdDKwAegC1EbEl7e8OoE7SPcCLZMLHzMyKpN0wiIjfAcqxaflx+twL3JujvjxXv4jYxr+cZjIzsyLzJ5DNzMxhYGZmDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMyO8ZyIMlrZL0kqQtkm5L9Q9LWilpa/rZP9UlaYGkRkkbJY3J2tes1H6rpFlZ9bGSNqU+C9Jzl83MrEjyOTI4BHw9IoYD44G5koYD84BnImIo8ExaB5gCDE2vOcBCyIQHcBdwGZlHXN51JEBSmxuz+tWc/NTMzCxf7YZBRLwVEevT8gHgZWAQMB1YnJotBmak5enAY5GxBugnaSAwGVgZEXsiYi+wEqhJ286JiDUREcBjWfsyM7Mi6NA1A0lVwGjgeeD8iHgrbXobOD8tDwJ2ZHVrSrXj1Zty1HO9/xxJDZIaWlpaOjJ0MzM7jrzDQNLZwC+Ar0bEH7O3pb/oo5PHdoyIWBQR1RFRXVFRUei3MzMrGXmFgaQyMkHweET8QyrvTKd4SD93pXozMDire2WqHa9emaNuZmZFks/dRAIeBV6OiAeyNtUDR+4ImgU8mVW/Pt1VNB7Yn04nrQAmSeqfLhxPAlakbX+UND691/VZ+zIzsyLomUeby4EvAZskbUi1vwPuA5ZKmg28AVyTti0HpgKNwHvADQARsUfS3cDa1O67EbEnLd8E/AQ4C3gqvczMrEjaDYOI+B3Q1n3/E3O0D2BuG/uqBWpz1BuAke2NxczMCsOfQDYzM4eBmZk5DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzMjv2cg10raJWlzVm2+pGZJG9Jrata2OyU1SnpV0uSsek2qNUqal1UfIun5VH9C0pmdOUEzM2tfPkcGPwFqctQfjIhR6bUcQNJwYCYwIvV5RFIPST2Ah4EpwHDgutQW4P60r48Ae4HZJzMhMzPruHbDICJWA3vaa5dMB+oi4mBEvA40AuPSqzEitkXEn4E6YLokAVcAy1L/xcCMjk3BzMxO1slcM7hZ0sZ0Gql/qg0CdmS1aUq1tuoDgH0RcahVPSdJcyQ1SGpoaWk5iaGbmVm2Ew2DhcDFwCjgLeAHnTWg44mIRRFRHRHVFRUVxXhLM7OS0PNEOkXEziPLkn4M/DKtNgODs5pWphpt1HcD/ST1TEcH2e3NzKxITujIQNLArNUrgSN3GtUDMyX1kjQEGAq8AKwFhqY7h84kc5G5PiICWAVclfrPAp48kTGZmdmJa/fIQNLPgQlAuaQm4C5ggqRRQADbgS8DRMQWSUuBl4BDwNyIOJz2czOwAugB1EbElvQWdwB1ku4BXgQe7azJmZlZftoNg4i4Lke5zV/YEXEvcG+O+nJgeY76NjJ3G5mZWRfxJ5DNzMxhYGZmDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMyCMMJNVK2iVpc1btw5JWStqafvZPdUlaIKlR0kZJY7L6zErtt0qalVUfK2lT6rNAkjp7kmZmdnz5HBn8BKhpVZsHPBMRQ4Fn0jrAFGBoes0BFkImPMg8O/kyMo+4vOtIgKQ2N2b1a/1eZmZWYO2GQUSsBva0Kk8HFqflxcCMrPpjkbEG6CdpIDAZWBkReyJiL7ASqEnbzomINRERwGNZ+zIzsyI50WsG50fEW2n5beD8tDwI2JHVrinVjldvylHPSdIcSQ2SGlpaWk5w6GZm1tpJX0BOf9FHJ4wln/daFBHVEVFdUVFRjLc0MysJJxoGO9MpHtLPXaneDAzOaleZaserV+aom5lZEZ1oGNQDR+4ImgU8mVW/Pt1VNB7Yn04nrQAmSeqfLhxPAlakbX+UND7dRXR91r7MzKxIerbXQNLPgQlAuaQmMncF3QcslTQbeAO4JjVfDkwFGoH3gBsAImKPpLuBtanddyPiyEXpm8jcsXQW8FR6mZlZEbUbBhFxXRubJuZoG8DcNvZTC9TmqDcAI9sbh5mZFY4/gWxmZg4DMzNzGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzMxwGZmbGSYaBpO2SNknaIKkh1T4saaWkreln/1SXpAWSGiVtlDQmaz+zUvutkma19X5mZlYYnXFk8JmIGBUR1Wl9HvBMRAwFnknrAFOAoek1B1gImfAg81zly4BxwF1HAsTMzIqjEKeJpgOL0/JiYEZW/bHIWAP0kzQQmAysjIg9EbEXWAnUFGBcZmbWhp4n2T+ApyUF8PcRsQg4PyLeStvfBs5Py4OAHVl9m1KtrfoxJM0hc1TBRRdddJJDP775z85vv1E+bYD5+TUzs26ss36nFOr3ycmGwb+NiGZJ5wErJb2SvTEiIgVFp0hhswigurq60/ZrZlbqTuo0UUQ0p5+7gH8kc85/Zzr9Q/q5KzVvBgZnda9MtbbqZmZWJCccBpI+JKnvkWVgErAZqAeO3BE0C3gyLdcD16e7isYD+9PppBXAJEn904XjSalmZmZFcjKnic4H/lHSkf0siYj/K2ktsFTSbOAN4JrUfjkwFWgE3gNuAIiIPZLuBtamdt+NiD0nMS4zM+ugEw6DiNgGfDxHfTcwMUc9gLlt7KsWqD3RsZiZ2cnxJ5DNzMxhYGZmDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMOIXCQFKNpFclNUqa19XjMTMrJadEGEjqATwMTAGGA9dJGt61ozIzKx2nRBgA44DGiNgWEX8G6oDpXTwmM7OSocxz6rt4ENJVQE1E/Oe0/iXgsoi4uVW7OcCctPpR4NU836IceKeThnu6KdW5e96lpVTnDR2f+19FREXrYs/OG0/hRcQiYFFH+0lqiIjqAgzplFeqc/e8S0upzhs6b+6nymmiZmBw1nplqpmZWRGcKmGwFhgqaYikM4GZQH0Xj8nMrGScEqeJIuKQpJuBFUAPoDYitnTiW3T41FI3Uqpz97xLS6nOGzpp7qfEBWQzM+tap8ppIjMz60IOAzMz615h0N5XWkjqJemJtP15SVVdMMxOl8e8/1bSS5I2SnpG0l91xTgLId+vMZH0nySFpG5x+2E+85Z0Tfp33yJpSbHHWAh5/Ld+kaRVkl5M/71P7YpxdjZJtZJ2SdrcxnZJWpD+d9koaUyH3yQiusWLzIXn14B/A5wJ/B4Y3qrNTcCP0vJM4ImuHneR5v0ZoE9a/kp3mHe+c0/t+gKrgTVAdVePu0j/5kOBF4H+af28rh53kea9CPhKWh4ObO/qcXfS3D8NjAE2t7F9KvAUIGA88HxH36M7HRnk85UW04HFaXkZMFGSijjGQmh33hGxKiLeS6tryHyOozvI92tM7gbuBz4o5uAKKJ953wg8HBF7ASJiV5HHWAj5zDuAc9LyucCbRRxfwUTEamDPcZpMBx6LjDVAP0kDO/Ie3SkMBgE7stabUi1nm4g4BOwHBhRldIWTz7yzzSbzF0R30O7c0+Hy4Ij4VTEHVmD5/Jv/NfDXkv6fpDWSaoo2usLJZ97zgS9KagKWA7cUZ2hdrqO/B45xSnzOwIpD0heBauDfdfVYikHSGcADwN908VC6Qk8yp4omkDkSXC3pkojY15WDKoLrgJ9ExA8kfRL4qaSREfHPXT2wU113OjLI5ystjraR1JPMYeTuooyucPL6Kg9J/x74r8C0iDhYpLEVWntz7wuMBJ6VtJ3MudT6bnAROZ9/8yagPiL+EhGvA38gEw6ns3zmPRtYChARzwG9yXyRW3d30l/p053CIJ+vtKgHZqXlq4DfRLr6chprd96SRgN/TyYIusO54yOOO/eI2B8R5RFRFRFVZK6XTIuIhq4ZbqfJ57/1/0PmqABJ5WROG20r4hgLIZ95/xMwEUDSMDJh0FLUUXaNeuD6dFfReGB/RLzVkR10m9NE0cZXWkj6LtAQEfXAo2QOGxvJXIyZ2XUj7hx5zvt7wNnA/07Xy/8pIqZ12aA7SZ5z73bynPcKYJKkl4DDwO0RcVofBec5768DP5b0NTIXk/+mG/zBh6Sfkwn38nQ95C6gDCAifkTm+shUoBF4D7ihw+/RDf53MjOzk9SdThOZmdkJchiYmZnDwMzMHAZmZobDwMzMcBiYmRkOAzMzA/4/TnkRM8NuLDQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train:Valid:Test = 8:1:1\n",
        "train_df, test_df = train_test_split(df, test_size =0.2, random_state= 42)\n",
        "valid_df, test_df = train_test_split(test_df, test_size =0.5, random_state= 42)\n",
        "\n",
        "bins = np.linspace(0, 1, 10)\n",
        "plt.hist([train_df['label'],valid_df['label'],test_df['label']],bins=bins,color=['r','g','b'],alpha=0.5,label=['train','valid','test'])\n",
        "plt.legend(loc='upper center')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NhZtdagGsTVe"
      },
      "source": [
        "### STEP 4. 벡터화 진행 (Vectorization)\n",
        "* 해당 실습에서는 모델 내부에서 벡터화를 진행합니다\n",
        "  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6v2UDIcOEoKb"
      },
      "source": [
        "### STEP 5. Dataset 구축하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FccIag2VHAFz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, df, tokenizer, max_seq_length=100):\n",
        "    self.max_seq_length = max_seq_length\n",
        "    self.tokenizer = tokenizer\n",
        "    self.df = df\n",
        "    self.inputs = df[\"normalize_sentence\"].to_list() # input sentence는 input 혹은 source라는 단어로 표현됨\n",
        "    self.targets = df[\"label\"].to_list() # output label은 target으로 표현됨\n",
        "\n",
        "    self.vocab = self.tokenizer.vocab\n",
        "    self.pad_idx = self.vocab['[PAD]']\n",
        "    self.cls_idx = self.vocab['[CLS]']\n",
        "    self.sep_idx = self.vocab['[SEP]']\n",
        "    self.mask_idx = self.vocab['[MASK]']\n",
        "\n",
        "  def convert_inputs_to_feature(self, input):\n",
        "    # STEP 1 : word to index\n",
        "    # 문장을 token 단위로 분리한 후, 모델이 이해할 수 있는 형태인 숫자로 바꾸어줍니다\n",
        "\n",
        "    tokenized_input = self.tokenizer.encode(input)\n",
        "\n",
        "\n",
        "    # STEP 2 : pad or truncate token\n",
        "    # max length에 따라 input 문장의 길이 조절하여 동일한 길이의 input으로 변환\n",
        "    # batch단위로 학습을 하기위해 다음과 같은 과정을 거침\n",
        "    diff = self.max_seq_length - len(tokenized_input)\n",
        "    if diff > 0:\n",
        "      tokenized_input += [self.pad_idx] * diff \n",
        "    else:\n",
        "      tokenized_input = tokenized_input[:self.max_seq_length-1] + [self.sep_idx]\n",
        "    \n",
        "    return tokenized_input\n",
        "\n",
        "  def idx2mask(self, token_ids):\n",
        "    # output bool; attention mask 생성\n",
        "    return [token_id != self.pad_idx for token_id in token_ids]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    input = self.inputs[idx]\n",
        "    target = self.targets[idx]\n",
        "\n",
        "    tokenized_input = self.convert_inputs_to_feature(input)\n",
        "    att_mask = self.idx2mask(tokenized_input)\n",
        "\n",
        "    # print(len(tokenized_input))\n",
        "    # print(self.max_seq_length)\n",
        "\n",
        "    # tokenized input이 max_seq_length와 같은지 무조건 체크\n",
        "    # att_mask가 max_seq_length와 같은지 무조건 체크\n",
        "    assert len(tokenized_input) == self.max_seq_length\n",
        "    assert len(att_mask) == self.max_seq_length\n",
        "\n",
        "    batch = [\n",
        "            torch.tensor(tokenized_input),\n",
        "            torch.tensor(att_mask),\n",
        "            torch.tensor(target),\n",
        "    ]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3XQ_y3wDp6sr"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 50\n",
        "\n",
        "train_dataset = BERTDataset(\n",
        "    df = train_df,\n",
        "    tokenizer = tokenizer,\n",
        "    max_seq_length=30)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    )\n",
        "\n",
        "valid_dataset = BERTDataset(\n",
        "    df = valid_df,\n",
        "    tokenizer = tokenizer,\n",
        "    max_seq_length=30)\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    dataset = valid_dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx_RHmwR7XMm",
        "outputId": "feb1b402-6266-434b-836e-cd5a76cf8957"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification , AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "# Huggingface에서 모델 불러오기\n",
        "model = BertForSequenceClassification.from_pretrained('klue/bert-base') #klue 데이터로 사전학습 된 체크포인트\n",
        "model = model.to(device)\n",
        "\n",
        "# 모델 내 parameter 업데이트를 위한 함수\n",
        "LR = 1e-5\n",
        "optimizer = AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "# Loss 함수 구하기\n",
        "criterion = CrossEntropyLoss()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TtJL9ZZ9yIGK"
      },
      "source": [
        "### 학습 Hyperparameter 설정\n",
        "  (1) Epoch 수  \n",
        "  (2) Validation 실시 조건: 몇 번의 batch마다 검증을 할 것인가  \n",
        "  (3) accumulation step 이용: 몇 개의 batch 마다 loss에 대해 업데이트 할 것인가"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P4zznG00FNEP"
      },
      "source": [
        "### (1) Epoch ver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nUiZVg976-v",
        "outputId": "7a38fb4a-c44b-4512-c3dc-0ff17a39f604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train | [1/5] [79/1600] | loss: 0.283583 | Acc: 0.900000 | F1: 0.894914\n",
            "Train | [1/5] [159/1600] | loss: 0.311968 | Acc: 0.900000 | F1: 0.899960\n",
            "Train | [1/5] [239/1600] | loss: 0.196806 | Acc: 0.940000 | F1: 0.936948\n",
            "Train | [1/5] [319/1600] | loss: 0.331560 | Acc: 0.880000 | F1: 0.879227\n",
            "Train | [1/5] [399/1600] | loss: 0.204433 | Acc: 0.960000 | F1: 0.960000\n",
            "Train | [1/5] [479/1600] | loss: 0.190118 | Acc: 0.940000 | F1: 0.936948\n",
            "Train | [1/5] [559/1600] | loss: 0.256224 | Acc: 0.900000 | F1: 0.896652\n",
            "Train | [1/5] [639/1600] | loss: 0.229275 | Acc: 0.920000 | F1: 0.913194\n",
            "Train | [1/5] [719/1600] | loss: 0.294918 | Acc: 0.880000 | F1: 0.879808\n",
            "Train | [1/5] [799/1600] | loss: 0.154131 | Acc: 0.940000 | F1: 0.939783\n",
            "Train | [1/5] [879/1600] | loss: 0.114171 | Acc: 0.980000 | F1: 0.979992\n",
            "Train | [1/5] [959/1600] | loss: 0.162619 | Acc: 0.900000 | F1: 0.899639\n",
            "Train | [1/5] [1039/1600] | loss: 0.374205 | Acc: 0.860000 | F1: 0.859494\n",
            "Train | [1/5] [1119/1600] | loss: 0.186999 | Acc: 0.920000 | F1: 0.917898\n",
            "Train | [1/5] [1199/1600] | loss: 0.197921 | Acc: 0.920000 | F1: 0.919485\n",
            "Train | [1/5] [1279/1600] | loss: 0.247865 | Acc: 0.940000 | F1: 0.937991\n",
            "Train | [1/5] [1359/1600] | loss: 0.188300 | Acc: 0.920000 | F1: 0.919485\n",
            "Train | [1/5] [1439/1600] | loss: 0.322056 | Acc: 0.880000 | F1: 0.878247\n",
            "Train | [1/5] [1519/1600] | loss: 0.267994 | Acc: 0.880000 | F1: 0.880000\n",
            "Train | [1/5] [1599/1600] | loss: 0.351025 | Acc: 0.880000 | F1: 0.879808\n",
            "Valid | [1/5] | loss: 0.205494 | Acc: 0.925700 | F1: 0.924256\n",
            "Best Accuracy 0.000% to 92.570%\n",
            "Train | [2/5] [79/1600] | loss: 0.301295 | Acc: 0.920000 | F1: 0.915110\n",
            "Train | [2/5] [159/1600] | loss: 0.116972 | Acc: 0.960000 | F1: 0.959416\n",
            "Train | [2/5] [239/1600] | loss: 0.172353 | Acc: 0.920000 | F1: 0.910873\n",
            "Train | [2/5] [319/1600] | loss: 0.115969 | Acc: 0.960000 | F1: 0.958333\n",
            "Train | [2/5] [399/1600] | loss: 0.206283 | Acc: 0.920000 | F1: 0.919485\n",
            "Train | [2/5] [479/1600] | loss: 0.163133 | Acc: 0.960000 | F1: 0.959936\n",
            "Train | [2/5] [559/1600] | loss: 0.336516 | Acc: 0.860000 | F1: 0.859944\n",
            "Train | [2/5] [639/1600] | loss: 0.049443 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [2/5] [719/1600] | loss: 0.045102 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [2/5] [799/1600] | loss: 0.230426 | Acc: 0.880000 | F1: 0.872666\n",
            "Train | [2/5] [879/1600] | loss: 0.242797 | Acc: 0.880000 | F1: 0.875000\n",
            "Train | [2/5] [959/1600] | loss: 0.341377 | Acc: 0.900000 | F1: 0.899960\n",
            "Train | [2/5] [1039/1600] | loss: 0.102324 | Acc: 0.980000 | F1: 0.978022\n",
            "Train | [2/5] [1119/1600] | loss: 0.128037 | Acc: 0.960000 | F1: 0.960000\n",
            "Train | [2/5] [1199/1600] | loss: 0.184491 | Acc: 0.920000 | F1: 0.916667\n",
            "Train | [2/5] [1279/1600] | loss: 0.071604 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [2/5] [1359/1600] | loss: 0.072328 | Acc: 0.980000 | F1: 0.979798\n",
            "Train | [2/5] [1439/1600] | loss: 0.079238 | Acc: 0.960000 | F1: 0.959416\n",
            "Train | [2/5] [1519/1600] | loss: 0.111857 | Acc: 0.960000 | F1: 0.959936\n",
            "Train | [2/5] [1599/1600] | loss: 0.256723 | Acc: 0.900000 | F1: 0.898990\n",
            "Valid | [2/5] | loss: 0.198409 | Acc: 0.928300 | F1: 0.926823\n",
            "Best Accuracy 92.570% to 92.830%\n",
            "Train | [3/5] [79/1600] | loss: 0.129640 | Acc: 0.920000 | F1: 0.918831\n",
            "Train | [3/5] [159/1600] | loss: 0.045831 | Acc: 0.980000 | F1: 0.979928\n",
            "Train | [3/5] [239/1600] | loss: 0.030633 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [3/5] [319/1600] | loss: 0.087587 | Acc: 0.980000 | F1: 0.978550\n",
            "Train | [3/5] [399/1600] | loss: 0.180553 | Acc: 0.960000 | F1: 0.958333\n",
            "Train | [3/5] [479/1600] | loss: 0.163851 | Acc: 0.920000 | F1: 0.919485\n",
            "Train | [3/5] [559/1600] | loss: 0.132240 | Acc: 0.980000 | F1: 0.979330\n",
            "Train | [3/5] [639/1600] | loss: 0.118698 | Acc: 0.940000 | F1: 0.939976\n",
            "Train | [3/5] [719/1600] | loss: 0.066049 | Acc: 0.960000 | F1: 0.958949\n",
            "Train | [3/5] [799/1600] | loss: 0.171965 | Acc: 0.920000 | F1: 0.920000\n",
            "Train | [3/5] [879/1600] | loss: 0.186991 | Acc: 0.940000 | F1: 0.939783\n",
            "Train | [3/5] [959/1600] | loss: 0.099106 | Acc: 0.960000 | F1: 0.958949\n",
            "Train | [3/5] [1039/1600] | loss: 0.144814 | Acc: 0.960000 | F1: 0.959416\n",
            "Train | [3/5] [1119/1600] | loss: 0.140896 | Acc: 0.980000 | F1: 0.979798\n",
            "Train | [3/5] [1199/1600] | loss: 0.107858 | Acc: 0.940000 | F1: 0.939783\n",
            "Train | [3/5] [1279/1600] | loss: 0.109010 | Acc: 0.960000 | F1: 0.959936\n",
            "Train | [3/5] [1359/1600] | loss: 0.119257 | Acc: 0.940000 | F1: 0.939394\n",
            "Train | [3/5] [1439/1600] | loss: 0.114260 | Acc: 0.980000 | F1: 0.979992\n",
            "Train | [3/5] [1519/1600] | loss: 0.190124 | Acc: 0.960000 | F1: 0.959416\n",
            "Train | [3/5] [1599/1600] | loss: 0.162307 | Acc: 0.940000 | F1: 0.937991\n",
            "Valid | [3/5] | loss: 0.223839 | Acc: 0.925100 | F1: 0.923558\n",
            "Train | [4/5] [79/1600] | loss: 0.058065 | Acc: 0.980000 | F1: 0.979928\n",
            "Train | [4/5] [159/1600] | loss: 0.018446 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [4/5] [239/1600] | loss: 0.099428 | Acc: 0.980000 | F1: 0.979928\n",
            "Train | [4/5] [319/1600] | loss: 0.025547 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [4/5] [399/1600] | loss: 0.084679 | Acc: 0.960000 | F1: 0.958333\n",
            "Train | [4/5] [479/1600] | loss: 0.049918 | Acc: 0.980000 | F1: 0.979600\n",
            "Train | [4/5] [559/1600] | loss: 0.033573 | Acc: 0.980000 | F1: 0.978983\n",
            "Train | [4/5] [639/1600] | loss: 0.097558 | Acc: 0.980000 | F1: 0.979330\n",
            "Train | [4/5] [719/1600] | loss: 0.084013 | Acc: 0.980000 | F1: 0.979798\n",
            "Train | [4/5] [799/1600] | loss: 0.146370 | Acc: 0.960000 | F1: 0.959416\n",
            "Train | [4/5] [879/1600] | loss: 0.066786 | Acc: 0.960000 | F1: 0.959936\n",
            "Train | [4/5] [959/1600] | loss: 0.011435 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [4/5] [1039/1600] | loss: 0.034493 | Acc: 0.980000 | F1: 0.979992\n",
            "Train | [4/5] [1119/1600] | loss: 0.004921 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [4/5] [1199/1600] | loss: 0.079161 | Acc: 0.960000 | F1: 0.958333\n",
            "Train | [4/5] [1279/1600] | loss: 0.143019 | Acc: 0.940000 | F1: 0.939394\n",
            "Train | [4/5] [1359/1600] | loss: 0.091732 | Acc: 0.960000 | F1: 0.959742\n",
            "Train | [4/5] [1439/1600] | loss: 0.007317 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [4/5] [1519/1600] | loss: 0.046565 | Acc: 0.980000 | F1: 0.979928\n",
            "Train | [4/5] [1599/1600] | loss: 0.115735 | Acc: 0.960000 | F1: 0.959936\n",
            "Valid | [4/5] | loss: 0.289153 | Acc: 0.923500 | F1: 0.921911\n",
            "Train | [5/5] [79/1600] | loss: 0.008510 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [159/1600] | loss: 0.002783 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [239/1600] | loss: 0.027929 | Acc: 0.980000 | F1: 0.979600\n",
            "Train | [5/5] [319/1600] | loss: 0.007393 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [399/1600] | loss: 0.005415 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [479/1600] | loss: 0.002510 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [559/1600] | loss: 0.050752 | Acc: 0.980000 | F1: 0.978550\n",
            "Train | [5/5] [639/1600] | loss: 0.011803 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [719/1600] | loss: 0.028135 | Acc: 0.980000 | F1: 0.979928\n",
            "Train | [5/5] [799/1600] | loss: 0.003463 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [879/1600] | loss: 0.009902 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [959/1600] | loss: 0.090180 | Acc: 0.940000 | F1: 0.939394\n",
            "Train | [5/5] [1039/1600] | loss: 0.033400 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [1119/1600] | loss: 0.022560 | Acc: 0.980000 | F1: 0.979992\n",
            "Train | [5/5] [1199/1600] | loss: 0.010739 | Acc: 1.000000 | F1: 1.000000\n",
            "Train | [5/5] [1279/1600] | loss: 0.076583 | Acc: 0.980000 | F1: 0.979600\n",
            "Train | [5/5] [1359/1600] | loss: 0.048051 | Acc: 0.960000 | F1: 0.958949\n",
            "Train | [5/5] [1439/1600] | loss: 0.064839 | Acc: 0.960000 | F1: 0.959416\n",
            "Train | [5/5] [1519/1600] | loss: 0.052977 | Acc: 0.980000 | F1: 0.979928\n",
            "Train | [5/5] [1599/1600] | loss: 0.015309 | Acc: 1.000000 | F1: 1.000000\n",
            "Valid | [5/5] | loss: 0.344899 | Acc: 0.921000 | F1: 0.919423\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def convert_device(device,*args):\n",
        "  return [arg.to(device) for arg in args]\n",
        "\n",
        "def get_scores(targets,logit):\n",
        "  preds = torch.argmax(F.softmax(logit),dim=1).cpu().detach().numpy()\n",
        "  targets = targets.cpu().detach().numpy()\n",
        "  acc = accuracy_score(targets,preds)\n",
        "  f1 = f1_score(targets, preds, average = 'macro')\n",
        "  return acc, f1\n",
        "\n",
        "def get_mean_scores(*args):\n",
        "  return [np.mean(arg) for arg in args]\n",
        "\n",
        "\n",
        "  \n",
        "# train\n",
        "EPOCH = 5\n",
        "LOG_INTERVAL = int(len(train_loader)*0.05) # 총 trainset의 batch 개수의 10% 씩 학습이 이루어진 후 검증 진행\n",
        "model.train()\n",
        "\n",
        "savedir = os.path.join('/content/results/','Epoch_ver')\n",
        "os.makedirs(savedir, exist_ok=True)\n",
        "\n",
        "\n",
        "train_loss, train_acc, train_f1 = [],[],[]\n",
        "valid_loss, valid_acc, valid_f1 = [],[],[]\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    train_batch_loss_list, train_batch_acc_list, train_batch_f1_list = [],[],[]    \n",
        "    for step, batch in enumerate(train_loader):\n",
        "        inputs, att_mask, targets = batch\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        att_mask = att_mask.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=att_mask, labels=targets)\n",
        "        \n",
        "        train_batch_loss = outputs[0]\n",
        "        train_batch_logit = outputs[1]\n",
        "        \n",
        "        # loss\n",
        "        train_batch_loss_list.append(train_batch_loss.item())\n",
        "        train_batch_loss.backward()\n",
        "        \n",
        "        # scores\n",
        "        train_batch_acc, train_batch_f1 = get_scores(targets,train_batch_logit)\n",
        "        train_batch_acc_list.append(train_batch_acc)\n",
        "        train_batch_f1_list.append(train_batch_f1)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if (step+1) % LOG_INTERVAL == 0:\n",
        "            print('Train | [%d/%d] [%d/%d] | loss: %f | Acc: %f | F1: %f' % (epoch+1, EPOCH, step, len(train_loader), train_batch_loss.item(),train_batch_acc, train_batch_f1))\n",
        "\n",
        "    train_epoch_loss, train_epoch_acc, train_epoch_f1 = get_mean_scores(*[train_batch_loss_list,train_batch_acc_list,train_batch_f1_list])\n",
        "    \n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_acc.append(train_epoch_acc)\n",
        "    train_f1.append(train_epoch_f1)\n",
        "    \n",
        "    # evaluate  \n",
        "    valid_batch_loss_list, valid_batch_acc_list, valid_batch_f1_list = [],[],[]  \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for step, batch in enumerate(valid_loader):\n",
        "            inputs, att_mask, targets = convert_device(device,*batch)\n",
        "            outputs = model(inputs, attention_mask=att_mask, labels=targets)\n",
        "\n",
        "            valid_batch_loss = outputs[0].item()\n",
        "            valid_logit = outputs[1]\n",
        "\n",
        "            valid_batch_acc, valid_batch_f1 = get_scores(targets,valid_logit)\n",
        "            \n",
        "            valid_batch_loss_list.append(valid_batch_loss)\n",
        "            valid_batch_acc_list.append(valid_batch_acc)\n",
        "            valid_batch_f1_list.append(valid_batch_f1)\n",
        "    \n",
        "    valid_epoch_loss, valid_epoch_acc, valid_epoch_f1 = get_mean_scores(*[valid_batch_loss_list,valid_batch_acc_list,valid_batch_f1_list])\n",
        "    print('Valid | [%d/%d] | loss: %f | Acc: %f | F1: %f' % (epoch+1, EPOCH, valid_epoch_loss, valid_epoch_acc, valid_epoch_f1))\n",
        "\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "    valid_acc.append(valid_epoch_acc)\n",
        "    valid_f1.append(valid_epoch_f1)\n",
        "    \n",
        "    # checkpoint\n",
        "    if best_acc < valid_epoch_acc:\n",
        "        # save best score\n",
        "        state = {'best_step':epoch}\n",
        "        state.update({'best_acc':valid_epoch_acc,'best_f1':valid_epoch_f1})\n",
        "\n",
        "        # save best model\n",
        "        torch.save(model.state_dict(), os.path.join(savedir, f'best_model.pt'))\n",
        "        \n",
        "        print('Best Accuracy {0:.3%} to {1:.3%}'.format(best_acc, valid_epoch_acc))\n",
        "\n",
        "        best_acc = valid_epoch_acc\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "LOSS_RESULTS={'train':train_loss,'valid':valid_loss}\n",
        "ACC_RESULTS={'train':train_acc,'valid':valid_acc}\n",
        "F1_RESULTS={'train':train_f1,'valid':valid_f1}\n",
        "\n",
        "pd.DataFrame(LOSS_RESULTS).plot(title='Loss')\n",
        "pd.DataFrame(ACC_RESULTS).plot(title='Accuracy')\n",
        "pd.DataFrame(F1_RESULTS).plot(title='F1 Score')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-n8F_Jusrp7h"
      },
      "source": [
        "### 학습 완료된 모델 시험하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aluRaS3ap6st"
      },
      "outputs": [],
      "source": [
        "# 시험용 데이터셋 구축\n",
        "\n",
        "test_dataset = BERTDataset(\n",
        "    df = test_df,\n",
        "    tokenizer = tokenizer,\n",
        "    max_seq_length=30)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWQyhTHKp6st",
        "outputId": "aa6c245c-4735-4d75-a18f-4a1e260eec43"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "model_prediction = []\n",
        "test_label = []\n",
        "with torch.no_grad():\n",
        "    for step, batch in enumerate(test_loader):\n",
        "        inputs, att_mask, targets = batch\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        att_mask = att_mask.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(inputs, attention_mask=att_mask, labels=targets)\n",
        "        \n",
        "        logit = outputs[1]\n",
        "\n",
        "        preds = torch.argmax(F.softmax(logit),dim=1)\n",
        "        preds = preds.cpu().detach().numpy()\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "\n",
        "        model_prediction.extend(preds)\n",
        "        test_label.extend(targets)\n",
        "        assert len(model_prediction) == len(test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb44_duzWKk1",
        "outputId": "a86f9ef0-d0ff-49f2-c5c3-919a88c46b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data f1 score :  0.9156868260665729\n",
            "Test data accuracy score :  0.9157\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# 성능 평가하기\n",
        "print('Test data f1 score : ',f1_score(test_label, model_prediction, average='macro'))\n",
        "print('Test data accuracy score : ',accuracy_score(test_label, model_prediction))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MnAslQjvEOcI"
      },
      "source": [
        "### (2) 실험ver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xJGGamz10kM-"
      },
      "outputs": [],
      "source": [
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, confusion_matrix\n",
        "import transformers\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "\n",
        "def training(model,\n",
        "             num_training_steps: int,\n",
        "             trainloader, \n",
        "             validloader,\n",
        "             criterion,\n",
        "             optimizer,\n",
        "             log_interval: int, \n",
        "             eval_interval: int, \n",
        "             savedir: str, \n",
        "             accumulation_steps: int = 1, \n",
        "             device: str = 'cpu'):\n",
        "  \n",
        "    batch_time_m = AverageMeter()\n",
        "    data_time_m = AverageMeter()\n",
        "    acc_m = AverageMeter()\n",
        "    losses_m = AverageMeter()\n",
        "    best_acc = 0\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    step = 0\n",
        "    train_mode = True\n",
        "    while train_mode:\n",
        "        for batch in trainloader:\n",
        "            # batch\n",
        "            inputs, att_mask, targets = convert_device(device,*batch)\n",
        "            data_time_m.update(time.time() - end)\n",
        "\n",
        "            # optimizer condition\n",
        "            opt_cond = (step + 1) % accumulation_steps == 0\n",
        "\n",
        "            # predict\n",
        "            outputs = model(inputs, attention_mask=att_mask, labels=targets)\n",
        "            logit = outputs[1]\n",
        "            loss = criterion(logit, targets)\n",
        "            \n",
        "            # loss for accumulation steps\n",
        "            loss /= accumulation_steps        \n",
        "            loss.backward()\n",
        "\n",
        "            if opt_cond:\n",
        "                # loss update\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                losses_m.update(loss.item()*accumulation_steps)\n",
        "\n",
        "                # accuracy\n",
        "                preds = torch.argmax(F.softmax(logit),dim=1)\n",
        "                acc_m.update(targets.eq(preds).sum().item()/targets.size(0), n=targets.size(0))\n",
        "                \n",
        "                batch_time_m.update(time.time() - end)\n",
        "                \n",
        "                if ((step+1) // accumulation_steps) % log_interval == 0 or step == 0:\n",
        "                     \n",
        "                    print('TRAIN | [{:>4d}/{}] Loss: {loss.val:>6.4f} ({loss.avg:>6.4f}) '\n",
        "                                'Acc: {acc.avg:.3%} '\n",
        "                                'LR: {lr:.3e} '\n",
        "                                'Time: {batch_time.val:.3f}s ({batch_time.avg:.3f}) ' # {rate:>7.2f}/s ({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s) '\n",
        "                                'Data: {data_time.val:.3f} ({data_time.avg:.3f})'.format(\n",
        "                                (step+1)//accumulation_steps, num_training_steps, \n",
        "                                loss       = losses_m, \n",
        "                                acc        = acc_m, \n",
        "                                lr         = optimizer.param_groups[0]['lr'],\n",
        "                                batch_time = batch_time_m,\n",
        "                                data_time  = data_time_m))\n",
        "\n",
        "\n",
        "                if (((step+1) // accumulation_steps) % eval_interval == 0 and step != 0) or step+1 == num_training_steps: \n",
        "                    eval_metrics = evaluate(model, validloader, criterion, log_interval, device)\n",
        "                    model.train()\n",
        "\n",
        "                    eval_log = dict([(f'eval_{k}', v) for k, v in eval_metrics.items()])\n",
        "\n",
        "                    # checkpoint\n",
        "                    if best_acc < eval_metrics['acc']:\n",
        "                        # save best score\n",
        "                        state = {'best_step':step}\n",
        "                        state.update(eval_log)\n",
        "                        json.dump(state, open(os.path.join(savedir, 'best_score.json'),'w'), indent=4)\n",
        "\n",
        "                        # save best model\n",
        "                        torch.save(model.state_dict(), os.path.join(savedir, f'best_model.pt'))\n",
        "                        \n",
        "                        print('Best Accuracy {0:.3%} to {1:.3%}'.format(best_acc, eval_metrics['acc']))\n",
        "\n",
        "                        best_acc = eval_metrics['acc']\n",
        "\n",
        "            end = time.time()\n",
        "\n",
        "            step += 1\n",
        "\n",
        "            if (step // accumulation_steps) >= num_training_steps:\n",
        "                train_mode = False\n",
        "                break\n",
        "\n",
        "    # save best model\n",
        "    torch.save(model.state_dict(), os.path.join(savedir, f'latest_model.pt'))\n",
        "\n",
        "    print('Best Metric: {0:.3%} (step {1:})'.format(best_acc, state['best_step']))\n",
        "    \n",
        "        \n",
        "def evaluate(model, dataloader, criterion, log_interval: int, device: str = 'cpu', sample_check: bool = False):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    total_score = []\n",
        "    total_preds = []\n",
        "    total_targets = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(dataloader):\n",
        "            inputs, att_mask, targets = convert_device(device,*batch)\n",
        "            \n",
        "            # predict\n",
        "            outputs = model(inputs, attention_mask=att_mask, labels=targets)\n",
        "            logit = outputs[1]\n",
        "\n",
        "            # loss \n",
        "            loss = criterion(logit, targets)\n",
        "            \n",
        "            # total loss and acc\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(F.softmax(logit),dim=1)\n",
        "\n",
        "            correct += targets.eq(preds).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            total_score.extend(logit.cpu().tolist())\n",
        "            total_preds.extend(preds.cpu().tolist())\n",
        "            total_targets.extend(targets.cpu().tolist())\n",
        "            \n",
        "            if idx % log_interval == 0 and idx != 0: \n",
        "                print('Validation log | [%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
        "                            (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total))\n",
        "            print()\n",
        "                \n",
        "    metrics = calc_metrics(\n",
        "        y_true  = total_targets,\n",
        "        y_score = np.array(total_score)[:,1],\n",
        "        y_pred  = total_preds\n",
        "    )\n",
        "    \n",
        "    metrics.update([('acc',correct/total), ('loss',total_loss/len(dataloader))])\n",
        "\n",
        "    print('Validation | Loss: %.3f | Acc: %.3f%% | AUROC: %.3f%% | F1-Score: %.3f%%' % \n",
        "                (metrics['loss'], 100.*metrics['acc'], 100.*metrics['auroc'], 100.*metrics['f1']))\n",
        "\n",
        "    if sample_check:\n",
        "        results = {\n",
        "            'targets': total_targets,\n",
        "            'preds'  : total_preds,\n",
        "            'outputs': total_score\n",
        "        }\n",
        "        return metrics, results\n",
        "    else:\n",
        "        return metrics\n",
        "\n",
        "\n",
        "def calc_metrics(y_true: list, y_score: np.ndarray, y_pred: list) -> dict:\n",
        "    auroc = roc_auc_score(y_true, y_score)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    print(f'TN: {tn}, FP: {fp}, FN: {fn}, tp: {tp}')\n",
        "\n",
        "    return {\n",
        "        'auroc'    : auroc, \n",
        "        'f1'       : f1, \n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aEUzJcoeBsQo",
        "outputId": "49303d2f-e73f-4536-ae68-64f01c9eb232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN | [   1/8000] Loss: 0.1014 (0.1014) Acc: 96.000% LR: 1.000e-05 Time: 0.166s (0.166) Data: 0.019 (0.019)\n",
            "TRAIN | [ 160/8000] Loss: 0.0630 (0.0625) Acc: 97.588% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.341 | Acc: 92.286% [7429/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4627, FP: 390, FN: 364, tp: 4619\n",
            "Validation | Loss: 0.333 | Acc: 92.460% | AUROC: 96.639% | F1-Score: 92.454%\n",
            "Best Accuracy 0.000% to 92.460%\n",
            "TRAIN | [ 320/8000] Loss: 0.0312 (0.0640) Acc: 97.500% LR: 1.000e-05 Time: 0.159s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.334 | Acc: 92.012% [7407/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4641, FP: 376, FN: 410, tp: 4573\n",
            "Validation | Loss: 0.327 | Acc: 92.140% | AUROC: 96.664% | F1-Score: 92.086%\n",
            "TRAIN | [ 480/8000] Loss: 0.1358 (0.0625) Acc: 97.612% LR: 1.000e-05 Time: 0.154s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.338 | Acc: 92.050% [7410/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4604, FP: 413, FN: 365, tp: 4618\n",
            "Validation | Loss: 0.333 | Acc: 92.220% | AUROC: 96.597% | F1-Score: 92.231%\n",
            "TRAIN | [ 640/8000] Loss: 0.1079 (0.0644) Acc: 97.572% LR: 1.000e-05 Time: 0.156s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.311 | Acc: 92.124% [7416/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4682, FP: 335, FN: 433, tp: 4550\n",
            "Validation | Loss: 0.306 | Acc: 92.320% | AUROC: 96.865% | F1-Score: 92.217%\n",
            "TRAIN | [ 800/8000] Loss: 0.1127 (0.0642) Acc: 97.552% LR: 1.000e-05 Time: 0.154s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.319 | Acc: 92.149% [7418/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4591, FP: 426, FN: 342, tp: 4641\n",
            "Validation | Loss: 0.314 | Acc: 92.320% | AUROC: 96.985% | F1-Score: 92.358%\n",
            "TRAIN | [ 960/8000] Loss: 0.0587 (0.0647) Acc: 97.531% LR: 1.000e-05 Time: 0.160s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.333 | Acc: 91.714% [7383/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4474, FP: 543, FN: 290, tp: 4693\n",
            "Validation | Loss: 0.331 | Acc: 91.670% | AUROC: 96.786% | F1-Score: 91.849%\n",
            "TRAIN | [1120/8000] Loss: 0.0561 (0.0640) Acc: 97.570% LR: 1.000e-05 Time: 0.155s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.319 | Acc: 92.211% [7423/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4587, FP: 430, FN: 351, tp: 4632\n",
            "Validation | Loss: 0.318 | Acc: 92.190% | AUROC: 96.807% | F1-Score: 92.225%\n",
            "TRAIN | [1280/8000] Loss: 0.0784 (0.0634) Acc: 97.584% LR: 1.000e-05 Time: 0.154s (0.157) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.321 | Acc: 92.137% [7417/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4646, FP: 371, FN: 410, tp: 4573\n",
            "Validation | Loss: 0.319 | Acc: 92.190% | AUROC: 96.575% | F1-Score: 92.133%\n",
            "TRAIN | [1440/8000] Loss: 0.0371 (0.0631) Acc: 97.604% LR: 1.000e-05 Time: 0.155s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.340 | Acc: 92.348% [7434/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4640, FP: 377, FN: 370, tp: 4613\n",
            "Validation | Loss: 0.335 | Acc: 92.530% | AUROC: 96.886% | F1-Score: 92.510%\n",
            "Best Accuracy 92.460% to 92.530%\n",
            "TRAIN | [1600/8000] Loss: 0.0247 (0.0633) Acc: 97.593% LR: 1.000e-05 Time: 0.155s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.312 | Acc: 92.186% [7421/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4626, FP: 391, FN: 396, tp: 4587\n",
            "Validation | Loss: 0.310 | Acc: 92.130% | AUROC: 96.558% | F1-Score: 92.099%\n",
            "TRAIN | [1760/8000] Loss: 0.0221 (0.0611) Acc: 97.678% LR: 1.000e-05 Time: 0.155s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.335 | Acc: 92.124% [7416/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4659, FP: 358, FN: 426, tp: 4557\n",
            "Validation | Loss: 0.333 | Acc: 92.160% | AUROC: 96.588% | F1-Score: 92.079%\n",
            "TRAIN | [1920/8000] Loss: 0.1268 (0.0595) Acc: 97.743% LR: 1.000e-05 Time: 0.155s (0.157) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.363 | Acc: 92.199% [7422/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4687, FP: 330, FN: 434, tp: 4549\n",
            "Validation | Loss: 0.358 | Acc: 92.360% | AUROC: 96.638% | F1-Score: 92.253%\n",
            "TRAIN | [2080/8000] Loss: 0.1737 (0.0589) Acc: 97.752% LR: 1.000e-05 Time: 0.165s (0.157) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.334 | Acc: 92.460% [7443/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4630, FP: 387, FN: 358, tp: 4625\n",
            "Validation | Loss: 0.334 | Acc: 92.550% | AUROC: 96.871% | F1-Score: 92.546%\n",
            "Best Accuracy 92.530% to 92.550%\n",
            "TRAIN | [2240/8000] Loss: 0.0192 (0.0577) Acc: 97.800% LR: 1.000e-05 Time: 0.155s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.351 | Acc: 92.161% [7419/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4670, FP: 347, FN: 422, tp: 4561\n",
            "Validation | Loss: 0.347 | Acc: 92.310% | AUROC: 96.771% | F1-Score: 92.225%\n",
            "TRAIN | [2400/8000] Loss: 0.0842 (0.0567) Acc: 97.841% LR: 1.000e-05 Time: 0.155s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.361 | Acc: 92.236% [7425/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4666, FP: 351, FN: 419, tp: 4564\n",
            "Validation | Loss: 0.359 | Acc: 92.300% | AUROC: 96.628% | F1-Score: 92.221%\n",
            "TRAIN | [2560/8000] Loss: 0.0249 (0.0558) Acc: 97.873% LR: 1.000e-05 Time: 0.156s (0.157) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.371 | Acc: 91.776% [7388/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4696, FP: 321, FN: 486, tp: 4497\n",
            "Validation | Loss: 0.368 | Acc: 91.930% | AUROC: 96.463% | F1-Score: 91.766%\n",
            "TRAIN | [2720/8000] Loss: 0.0371 (0.0559) Acc: 97.876% LR: 1.000e-05 Time: 0.166s (0.157) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.338 | Acc: 92.025% [7408/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4646, FP: 371, FN: 416, tp: 4567\n",
            "Validation | Loss: 0.335 | Acc: 92.130% | AUROC: 96.464% | F1-Score: 92.067%\n",
            "TRAIN | [2880/8000] Loss: 0.0694 (0.0552) Acc: 97.892% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.362 | Acc: 92.348% [7434/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4604, FP: 413, FN: 341, tp: 4642\n",
            "Validation | Loss: 0.356 | Acc: 92.460% | AUROC: 96.798% | F1-Score: 92.489%\n",
            "TRAIN | [3040/8000] Loss: 0.0041 (0.0550) Acc: 97.905% LR: 1.000e-05 Time: 0.156s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.339 | Acc: 91.975% [7404/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4604, FP: 413, FN: 372, tp: 4611\n",
            "Validation | Loss: 0.336 | Acc: 92.150% | AUROC: 96.607% | F1-Score: 92.155%\n",
            "TRAIN | [3200/8000] Loss: 0.0289 (0.0547) Acc: 97.926% LR: 1.000e-05 Time: 0.155s (0.157) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.319 | Acc: 92.037% [7409/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4662, FP: 355, FN: 424, tp: 4559\n",
            "Validation | Loss: 0.315 | Acc: 92.210% | AUROC: 96.704% | F1-Score: 92.129%\n",
            "TRAIN | [3360/8000] Loss: 0.0033 (0.0538) Acc: 97.964% LR: 1.000e-05 Time: 0.155s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.362 | Acc: 92.311% [7431/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4671, FP: 346, FN: 408, tp: 4575\n",
            "Validation | Loss: 0.361 | Acc: 92.460% | AUROC: 96.690% | F1-Score: 92.387%\n",
            "TRAIN | [3520/8000] Loss: 0.0920 (0.0530) Acc: 97.993% LR: 1.000e-05 Time: 0.154s (0.157) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.376 | Acc: 91.752% [7386/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4480, FP: 537, FN: 284, tp: 4699\n",
            "Validation | Loss: 0.374 | Acc: 91.790% | AUROC: 96.766% | F1-Score: 91.966%\n",
            "TRAIN | [3680/8000] Loss: 0.0337 (0.0524) Acc: 98.006% LR: 1.000e-05 Time: 0.155s (0.156) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.377 | Acc: 92.075% [7412/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4574, FP: 443, FN: 332, tp: 4651\n",
            "Validation | Loss: 0.373 | Acc: 92.250% | AUROC: 96.772% | F1-Score: 92.309%\n",
            "TRAIN | [3840/8000] Loss: 0.0226 (0.0517) Acc: 98.027% LR: 1.000e-05 Time: 0.156s (0.156) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.375 | Acc: 92.373% [7436/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4628, FP: 389, FN: 370, tp: 4613\n",
            "Validation | Loss: 0.373 | Acc: 92.410% | AUROC: 96.689% | F1-Score: 92.399%\n",
            "TRAIN | [4000/8000] Loss: 0.0272 (0.0510) Acc: 98.052% LR: 1.000e-05 Time: 0.155s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.368 | Acc: 91.863% [7395/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4625, FP: 392, FN: 413, tp: 4570\n",
            "Validation | Loss: 0.367 | Acc: 91.950% | AUROC: 96.558% | F1-Score: 91.905%\n",
            "TRAIN | [4160/8000] Loss: 0.0036 (0.0506) Acc: 98.070% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.363 | Acc: 92.298% [7430/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4695, FP: 322, FN: 437, tp: 4546\n",
            "Validation | Loss: 0.361 | Acc: 92.410% | AUROC: 96.673% | F1-Score: 92.295%\n",
            "TRAIN | [4320/8000] Loss: 0.0390 (0.0501) Acc: 98.089% LR: 1.000e-05 Time: 0.155s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.403 | Acc: 92.062% [7411/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4692, FP: 325, FN: 455, tp: 4528\n",
            "Validation | Loss: 0.400 | Acc: 92.200% | AUROC: 96.570% | F1-Score: 92.070%\n",
            "TRAIN | [4480/8000] Loss: 0.0390 (0.0498) Acc: 98.099% LR: 1.000e-05 Time: 0.157s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.375 | Acc: 91.851% [7394/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4671, FP: 346, FN: 455, tp: 4528\n",
            "Validation | Loss: 0.372 | Acc: 91.990% | AUROC: 96.581% | F1-Score: 91.874%\n",
            "TRAIN | [4640/8000] Loss: 0.0306 (0.0495) Acc: 98.118% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.356 | Acc: 91.988% [7405/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4605, FP: 412, FN: 374, tp: 4609\n",
            "Validation | Loss: 0.353 | Acc: 92.140% | AUROC: 96.729% | F1-Score: 92.143%\n",
            "TRAIN | [4800/8000] Loss: 0.0183 (0.0492) Acc: 98.127% LR: 1.000e-05 Time: 0.166s (0.156) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.372 | Acc: 92.012% [7407/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4681, FP: 336, FN: 451, tp: 4532\n",
            "Validation | Loss: 0.369 | Acc: 92.130% | AUROC: 96.770% | F1-Score: 92.011%\n",
            "TRAIN | [4960/8000] Loss: 0.0655 (0.0485) Acc: 98.150% LR: 1.000e-05 Time: 0.155s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.392 | Acc: 91.776% [7388/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4668, FP: 349, FN: 469, tp: 4514\n",
            "Validation | Loss: 0.391 | Acc: 91.820% | AUROC: 96.498% | F1-Score: 91.692%\n",
            "TRAIN | [5120/8000] Loss: 0.0059 (0.0478) Acc: 98.176% LR: 1.000e-05 Time: 0.156s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.399 | Acc: 92.149% [7418/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4703, FP: 314, FN: 461, tp: 4522\n",
            "Validation | Loss: 0.396 | Acc: 92.250% | AUROC: 96.666% | F1-Score: 92.107%\n",
            "TRAIN | [5280/8000] Loss: 0.0257 (0.0474) Acc: 98.197% LR: 1.000e-05 Time: 0.157s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.390 | Acc: 91.876% [7396/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4691, FP: 326, FN: 470, tp: 4513\n",
            "Validation | Loss: 0.387 | Acc: 92.040% | AUROC: 96.652% | F1-Score: 91.896%\n",
            "TRAIN | [5440/8000] Loss: 0.0318 (0.0470) Acc: 98.214% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.389 | Acc: 91.876% [7396/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4691, FP: 326, FN: 466, tp: 4517\n",
            "Validation | Loss: 0.384 | Acc: 92.080% | AUROC: 96.677% | F1-Score: 91.940%\n",
            "TRAIN | [5600/8000] Loss: 0.0535 (0.0466) Acc: 98.226% LR: 1.000e-05 Time: 0.153s (0.156) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.388 | Acc: 92.199% [7422/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4622, FP: 395, FN: 375, tp: 4608\n",
            "Validation | Loss: 0.386 | Acc: 92.300% | AUROC: 96.782% | F1-Score: 92.289%\n",
            "TRAIN | [5760/8000] Loss: 0.0020 (0.0462) Acc: 98.239% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.405 | Acc: 92.087% [7413/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4751, FP: 266, FN: 513, tp: 4470\n",
            "Validation | Loss: 0.400 | Acc: 92.210% | AUROC: 96.661% | F1-Score: 91.985%\n",
            "TRAIN | [5920/8000] Loss: 0.0137 (0.0459) Acc: 98.250% LR: 1.000e-05 Time: 0.155s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.363 | Acc: 92.348% [7434/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4633, FP: 384, FN: 382, tp: 4601\n",
            "Validation | Loss: 0.363 | Acc: 92.340% | AUROC: 96.728% | F1-Score: 92.315%\n",
            "TRAIN | [6080/8000] Loss: 0.0307 (0.0455) Acc: 98.262% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.400 | Acc: 92.062% [7411/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4610, FP: 407, FN: 391, tp: 4592\n",
            "Validation | Loss: 0.403 | Acc: 92.020% | AUROC: 96.576% | F1-Score: 92.006%\n",
            "TRAIN | [6240/8000] Loss: 0.0023 (0.0452) Acc: 98.273% LR: 1.000e-05 Time: 0.164s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.381 | Acc: 91.665% [7379/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4641, FP: 376, FN: 449, tp: 4534\n",
            "Validation | Loss: 0.377 | Acc: 91.750% | AUROC: 96.525% | F1-Score: 91.661%\n",
            "TRAIN | [6400/8000] Loss: 0.0619 (0.0450) Acc: 98.280% LR: 1.000e-05 Time: 0.152s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.368 | Acc: 92.248% [7426/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4651, FP: 366, FN: 393, tp: 4590\n",
            "Validation | Loss: 0.365 | Acc: 92.410% | AUROC: 96.857% | F1-Score: 92.363%\n",
            "TRAIN | [6560/8000] Loss: 0.0100 (0.0445) Acc: 98.297% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.395 | Acc: 92.186% [7421/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4603, FP: 414, FN: 355, tp: 4628\n",
            "Validation | Loss: 0.389 | Acc: 92.310% | AUROC: 96.927% | F1-Score: 92.329%\n",
            "TRAIN | [6720/8000] Loss: 0.0943 (0.0440) Acc: 98.316% LR: 1.000e-05 Time: 0.156s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.415 | Acc: 92.037% [7409/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4576, FP: 441, FN: 343, tp: 4640\n",
            "Validation | Loss: 0.414 | Acc: 92.160% | AUROC: 96.832% | F1-Score: 92.210%\n",
            "TRAIN | [6880/8000] Loss: 0.0010 (0.0435) Acc: 98.332% LR: 1.000e-05 Time: 0.154s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.412 | Acc: 92.559% [7451/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4690, FP: 327, FN: 404, tp: 4579\n",
            "Validation | Loss: 0.408 | Acc: 92.690% | AUROC: 96.886% | F1-Score: 92.608%\n",
            "Best Accuracy 92.550% to 92.690%\n",
            "TRAIN | [7040/8000] Loss: 0.0017 (0.0433) Acc: 98.342% LR: 1.000e-05 Time: 0.153s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.408 | Acc: 91.826% [7392/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4550, FP: 467, FN: 339, tp: 4644\n",
            "Validation | Loss: 0.405 | Acc: 91.940% | AUROC: 96.800% | F1-Score: 92.015%\n",
            "TRAIN | [7200/8000] Loss: 0.0349 (0.0429) Acc: 98.356% LR: 1.000e-05 Time: 0.155s (0.156) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.418 | Acc: 92.497% [7446/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4622, FP: 395, FN: 352, tp: 4631\n",
            "Validation | Loss: 0.414 | Acc: 92.530% | AUROC: 96.982% | F1-Score: 92.537%\n",
            "TRAIN | [7360/8000] Loss: 0.0211 (0.0426) Acc: 98.366% LR: 1.000e-05 Time: 0.163s (0.156) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.410 | Acc: 92.224% [7424/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4649, FP: 368, FN: 401, tp: 4582\n",
            "Validation | Loss: 0.410 | Acc: 92.310% | AUROC: 96.695% | F1-Score: 92.258%\n",
            "TRAIN | [7520/8000] Loss: 0.0297 (0.0423) Acc: 98.374% LR: 1.000e-05 Time: 0.157s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.401 | Acc: 92.037% [7409/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4667, FP: 350, FN: 442, tp: 4541\n",
            "Validation | Loss: 0.401 | Acc: 92.080% | AUROC: 96.668% | F1-Score: 91.979%\n",
            "TRAIN | [7680/8000] Loss: 0.0313 (0.0421) Acc: 98.379% LR: 1.000e-05 Time: 0.156s (0.156) Data: 0.006 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.393 | Acc: 92.050% [7410/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4662, FP: 355, FN: 422, tp: 4561\n",
            "Validation | Loss: 0.389 | Acc: 92.230% | AUROC: 96.716% | F1-Score: 92.151%\n",
            "TRAIN | [7840/8000] Loss: 0.0187 (0.0418) Acc: 98.388% LR: 1.000e-05 Time: 0.157s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.400 | Acc: 92.000% [7406/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4574, FP: 443, FN: 342, tp: 4641\n",
            "Validation | Loss: 0.398 | Acc: 92.150% | AUROC: 96.839% | F1-Score: 92.202%\n",
            "TRAIN | [8000/8000] Loss: 0.0054 (0.0416) Acc: 98.394% LR: 1.000e-05 Time: 0.155s (0.156) Data: 0.005 (0.006)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.390 | Acc: 92.224% [7424/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4671, FP: 346, FN: 419, tp: 4564\n",
            "Validation | Loss: 0.387 | Acc: 92.350% | AUROC: 96.801% | F1-Score: 92.267%\n",
            "Best Metric: 92.690% (step 6879)\n"
          ]
        }
      ],
      "source": [
        "num_training_steps = len(train_loader)*5\n",
        "log_interval = int(len(train_loader)*0.1)\n",
        "eval_interval = int(len(train_loader)*0.1)\n",
        "\n",
        "savedir = os.path.join('/content/results','Experiment_ver')\n",
        "os.makedirs(savedir, exist_ok=True)\n",
        "accumulation_steps = 1\n",
        "\n",
        "\n",
        "training(\n",
        "  model              = model,\n",
        "  num_training_steps = num_training_steps,\n",
        "  trainloader        = train_loader, \n",
        "  validloader        = valid_loader, \n",
        "  criterion          = criterion, \n",
        "  optimizer          = optimizer, \n",
        "  log_interval       = log_interval,\n",
        "  eval_interval      = eval_interval,\n",
        "  savedir            = savedir,\n",
        "  accumulation_steps = accumulation_steps,\n",
        "  device             = device,\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hZPh6uv3EYor"
      },
      "source": [
        "#### 학습 완료된 모델 시험하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vrCCHd-cEYos"
      },
      "outputs": [],
      "source": [
        "# 시험용 데이터셋 구축\n",
        "\n",
        "test_dataset = BERTDataset(\n",
        "    df = test_df,\n",
        "    tokenizer = tokenizer,\n",
        "    max_seq_length=30)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FaiZATi5EYot"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [21/200]: Loss: 0.407 | Acc: 91.429% [960/1050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [41/200]: Loss: 0.417 | Acc: 91.756% [1881/2050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [61/200]: Loss: 0.449 | Acc: 91.213% [2782/3050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [81/200]: Loss: 0.438 | Acc: 91.309% [3698/4050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [101/200]: Loss: 0.422 | Acc: 91.545% [4623/5050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [121/200]: Loss: 0.417 | Acc: 91.669% [5546/6050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [141/200]: Loss: 0.420 | Acc: 91.730% [6467/7050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [161/200]: Loss: 0.410 | Acc: 91.764% [7387/8050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Validation log | [181/200]: Loss: 0.408 | Acc: 91.812% [8309/9050]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TN: 4523, FP: 412, FN: 405, tp: 4660\n",
            "Validation | Loss: 0.405 | Acc: 91.830% | AUROC: 96.769% | F1-Score: 91.940%\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "num_test_steps = len(test_loader)\n",
        "log_interval = int(num_test_steps*0.1)\n",
        "eval_interval = int(num_test_steps*0.1)\n",
        "metrics, exp_results = evaluate(\n",
        "                    model        = model, \n",
        "                    dataloader   = test_loader, \n",
        "                    criterion    = criterion,\n",
        "                    log_interval = log_interval,\n",
        "                    device       = device,\n",
        "                    sample_check = True\n",
        "                )\n",
        "                \n",
        "# save result metrics\n",
        "json.dump(metrics, open(\"test_results.json\",'w'), indent='\\t')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s3sKCreSr9BE"
      },
      "source": [
        "Credits: Lee Yukyung, Doyoon Kim"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
